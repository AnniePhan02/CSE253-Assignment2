{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41fbdd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/anniephan/miniconda3/lib/python3.13/site-packages (2.7.0)\n",
      "Collecting pretty_midi\n",
      "  Downloading pretty_midi-0.2.10.tar.gz (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting matplotlib\n",
      "  Downloading matplotlib-3.10.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: filelock in /Users/anniephan/miniconda3/lib/python3.13/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/anniephan/miniconda3/lib/python3.13/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /Users/anniephan/miniconda3/lib/python3.13/site-packages (from torch) (78.1.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/anniephan/miniconda3/lib/python3.13/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/anniephan/miniconda3/lib/python3.13/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/anniephan/miniconda3/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/anniephan/miniconda3/lib/python3.13/site-packages (from torch) (2025.5.0)\n",
      "Requirement already satisfied: numpy>=1.7.0 in /Users/anniephan/miniconda3/lib/python3.13/site-packages (from pretty_midi) (2.2.5)\n",
      "Collecting mido>=1.1.16 (from pretty_midi)\n",
      "  Using cached mido-1.3.3-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: six in /Users/anniephan/miniconda3/lib/python3.13/site-packages (from pretty_midi) (1.17.0)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.58.0-cp313-cp313-macosx_10_13_universal2.whl.metadata (104 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/anniephan/miniconda3/lib/python3.13/site-packages (from matplotlib) (24.2)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.2.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (8.9 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/anniephan/miniconda3/lib/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/anniephan/miniconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/anniephan/miniconda3/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading matplotlib-3.10.3-cp313-cp313-macosx_11_0_arm64.whl (8.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.2-cp313-cp313-macosx_11_0_arm64.whl (255 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.58.0-cp313-cp313-macosx_10_13_universal2.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.8-cp313-cp313-macosx_11_0_arm64.whl (65 kB)\n",
      "Using cached mido-1.3.3-py3-none-any.whl (54 kB)\n",
      "Downloading pillow-11.2.1-cp313-cp313-macosx_11_0_arm64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Building wheels for collected packages: pretty_midi\n",
      "  Building wheel for pretty_midi (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pretty_midi: filename=pretty_midi-0.2.10-py3-none-any.whl size=5592344 sha256=e5e421e2c6fa5e912498ff77f7c745da4b76b551b2ed4b4c3ab45c2d585e3dcd\n",
      "  Stored in directory: /Users/anniephan/Library/Caches/pip/wheels/e7/e6/7e/02fa6cea25e454658c38e18040e05de4a2cb2ba6500d127970\n",
      "Successfully built pretty_midi\n",
      "Installing collected packages: pyparsing, pillow, mido, kiwisolver, fonttools, cycler, contourpy, pretty_midi, matplotlib\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.58.0 kiwisolver-1.4.8 matplotlib-3.10.3 mido-1.3.3 pillow-11.2.1 pretty_midi-0.2.10 pyparsing-3.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install torch pretty_midi matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76f4ce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pretty_midi\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23738d80",
   "metadata": {},
   "source": [
    "# Assignment 2 Music Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f73196",
   "metadata": {},
   "source": [
    "## About: \n",
    "\n",
    "### Task 1: \n",
    "We are using the LSTM model to predict the next note in a melody. \n",
    "- to extend it out, we might be able to do like rhythmic prediction\n",
    "- maybe also make our samples into note plots for peers to see\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdeba9a",
   "metadata": {},
   "source": [
    "## Task 1: Symbolic Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a158df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 229 training chorales.\n",
      "Sample: [(np.int64(60), np.int64(72), np.int64(79), np.int64(88)), (np.int64(72), np.int64(79), np.int64(88)), (np.int64(67), np.int64(70), np.int64(76), np.int64(84)), (np.int64(69), np.int64(77), np.int64(86)), (np.int64(67), np.int64(70), np.int64(79), np.int64(88))]\n"
     ]
    }
   ],
   "source": [
    "# Import in dataset\n",
    "import pickle\n",
    "\n",
    "with open(\"JSB-Chorales-dataset-master/jsb-chorales-quarter.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f, encoding=\"latin1\")\n",
    "\n",
    "chorales = data[\"train\"]  # You can also access 'valid' and 'test'\n",
    "\n",
    "print(f\"Loaded {len(chorales)} training chorales.\")\n",
    "print(\"Sample:\", chorales[0][:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09d5272",
   "metadata": {},
   "source": [
    "\n",
    "### Dataset Context\n",
    "The JSB Chorales dataset consists of 382 four-part harmonized chorales by J.S. Bach. It is widely used in symbolic music modeling and has been curated to support machine learning tasks. We use the version released by [Zhuang et al.](https://github.com/czhuang/JSB-Chorales-dataset), which contains quarter-note quantized sequences of chord events encoded as MIDI pitch tuples.\n",
    "\n",
    "We selected the **soprano voice** to build a monophonic melody model using an LSTM.\n",
    "\n",
    "### Preprocessing Steps\n",
    "- Extract first pitch in each chord (soprano line)\n",
    "- Remove silences/rests (`-1`)\n",
    "- Build vocabulary of MIDI pitches\n",
    "- Tokenize each melody to integer indices for model input\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f226d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocess Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5cd610",
   "metadata": {},
   "source": [
    "### Modeling Approach\n",
    "We formulate this as a next-token prediction task: given a sequence of pitches, the model predicts the next most likely note. This follows a standard language modeling approach in NLP.\n",
    "\n",
    "#### Model Choice: LSTM\n",
    "We use an LSTM because:\n",
    "- It can model temporal dependencies\n",
    "- It handles variable-length sequences\n",
    "- It's computationally efficient for our small vocabulary\n",
    "\n",
    "Alternatives include:\n",
    "- n-gram models: simpler, but limited context\n",
    "- Transformers: powerful, but more complex to train and tune\n",
    "\n",
    "We chose the LSTM as a middle ground between expressive power and implementation complexity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ec5577",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1675fe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate Samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c02c4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show note charts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b326626",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "We evaluate our model using:\n",
    "- Cross-entropy loss on held-out validation sequences\n",
    "- Subjective listening: Does the output follow tonal structure? Does it avoid dissonance? Is it musically coherent?\n",
    "\n",
    "We also compare against a trivial baseline: uniform sampling of notes from the vocabulary. The LSTM shows clear improvement in musical structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0941d1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evalluation + analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c48a521",
   "metadata": {},
   "source": [
    "## Task 2: Melody Harmonization\n",
    "We can use the JSB Chorale dataset. With this, we can generate a harmony to the songs. This can be done using a chord or baseline harmonization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35df7f2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
