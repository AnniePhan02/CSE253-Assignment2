{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41fbdd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/anniephan/miniconda3/lib/python3.13/site-packages (2.7.0)\n",
      "Requirement already satisfied: pretty_midi in /Users/anniephan/miniconda3/lib/python3.13/site-packages (0.2.10)\n",
      "Requirement already satisfied: matplotlib in /Users/anniephan/miniconda3/lib/python3.13/site-packages (3.10.3)\n",
      "Requirement already satisfied: filelock in /Users/anniephan/miniconda3/lib/python3.13/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/anniephan/miniconda3/lib/python3.13/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /Users/anniephan/miniconda3/lib/python3.13/site-packages (from torch) (78.1.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/anniephan/miniconda3/lib/python3.13/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/anniephan/miniconda3/lib/python3.13/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/anniephan/miniconda3/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/anniephan/miniconda3/lib/python3.13/site-packages (from torch) (2025.5.0)\n",
      "Requirement already satisfied: numpy>=1.7.0 in /Users/anniephan/miniconda3/lib/python3.13/site-packages (from pretty_midi) (2.2.5)\n",
      "Requirement already satisfied: mido>=1.1.16 in /Users/anniephan/miniconda3/lib/python3.13/site-packages (from pretty_midi) (1.3.3)\n",
      "Requirement already satisfied: six in /Users/anniephan/miniconda3/lib/python3.13/site-packages (from pretty_midi) (1.17.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/anniephan/miniconda3/lib/python3.13/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/anniephan/miniconda3/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/anniephan/miniconda3/lib/python3.13/site-packages (from matplotlib) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/anniephan/miniconda3/lib/python3.13/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/anniephan/miniconda3/lib/python3.13/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/anniephan/miniconda3/lib/python3.13/site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/anniephan/miniconda3/lib/python3.13/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/anniephan/miniconda3/lib/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/anniephan/miniconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/anniephan/miniconda3/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch pretty_midi matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76f4ce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pretty_midi\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23738d80",
   "metadata": {},
   "source": [
    "# Assignment 2 Music Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f73196",
   "metadata": {},
   "source": [
    "## About: \n",
    "\n",
    "### Task 1: \n",
    "We are using the LSTM model to predict the next note in a melody. \n",
    "- to extend it out, we might be able to do like rhythmic prediction\n",
    "- maybe also make our samples into note plots for peers to see\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdeba9a",
   "metadata": {},
   "source": [
    "## Task 1: Symbolic Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a158df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 229 training chorales.\n",
      "Sample: [(np.int64(60), np.int64(72), np.int64(79), np.int64(88)), (np.int64(72), np.int64(79), np.int64(88)), (np.int64(67), np.int64(70), np.int64(76), np.int64(84)), (np.int64(69), np.int64(77), np.int64(86)), (np.int64(67), np.int64(70), np.int64(79), np.int64(88))]\n"
     ]
    }
   ],
   "source": [
    "# Import in dataset\n",
    "import pickle\n",
    "\n",
    "with open(\"JSB-Chorales-dataset-master/jsb-chorales-quarter.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f, encoding=\"latin1\")\n",
    "\n",
    "chorales = data[\"train\"]  # You can also access 'valid' and 'test'\n",
    "\n",
    "print(f\"Loaded {len(chorales)} training chorales.\")\n",
    "print(\"Sample:\", chorales[0][:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09d5272",
   "metadata": {},
   "source": [
    "\n",
    "### Dataset Context\n",
    "The JSB Chorales dataset consists of 382 four-part harmonized chorales by J.S. Bach. It is widely used in symbolic music modeling and has been curated to support machine learning tasks. We use the version released by [Zhuang et al.](https://github.com/czhuang/JSB-Chorales-dataset), which contains quarter-note quantized sequences of chord events encoded as MIDI pitch tuples.\n",
    "\n",
    "We selected the **soprano voice** to build a monophonic melody model using an LSTM.\n",
    "\n",
    "### Preprocessing Steps\n",
    "- Extract first pitch in each chord (soprano line)\n",
    "- Remove silences/rests (`-1`)\n",
    "- Build vocabulary of MIDI pitches\n",
    "- Tokenize each melody to integer indices for model input\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8f226d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocess Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5cd610",
   "metadata": {},
   "source": [
    "### Modeling Approach\n",
    "We formulate this as a next-token prediction task: given a sequence of pitches, the model predicts the next most likely note. This follows a standard language modeling approach in NLP.\n",
    "\n",
    "#### Model Choice: LSTM\n",
    "We use an LSTM because:\n",
    "- It can model temporal dependencies\n",
    "- It handles variable-length sequences\n",
    "- It's computationally efficient for our small vocabulary\n",
    "\n",
    "Alternatives include:\n",
    "- n-gram models: simpler, but limited context\n",
    "- Transformers: powerful, but more complex to train and tune\n",
    "\n",
    "We chose the LSTM as a middle ground between expressive power and implementation complexity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16ec5577",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1675fe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate Samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c02c4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show note charts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b326626",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "We evaluate our model using:\n",
    "- Cross-entropy loss on held-out validation sequences\n",
    "- Subjective listening: Does the output follow tonal structure? Does it avoid dissonance? Is it musically coherent?\n",
    "\n",
    "We also compare against a trivial baseline: uniform sampling of notes from the vocabulary. The LSTM shows clear improvement in musical structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0941d1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evalluation + analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c48a521",
   "metadata": {},
   "source": [
    "## Task 2: Melody Harmonization\n",
    "We can use the JSB Chorale dataset. With this, we can generate a harmony to the songs. This can be done using a chord or baseline harmonization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35df7f2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
